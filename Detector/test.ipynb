{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alba/miniconda3/envs/cv4ecology/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a new YOLO model from scratch\n",
    "model = YOLO(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained YOLO model (recommended for training)\n",
    "model = YOLO(\"ct_classifier/weights/\" + MODEL_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alba/cv4ecology/ct_classifier\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.157 🚀 Python-3.8.17 torch-1.8.1+cu111 CUDA:0 (NVIDIA A40, 48548MiB)\n",
      "WARNING ⚠️ Upgrade to torch>=2.0.0 for deterministic training.\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=ct_classifier/weights/yolov8n.pt, data=aicensus.yaml, epochs=3, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train16\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    754237  ultralytics.nn.modules.head.Detect           [15, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3013773 parameters, 3013757 gradients\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning ../Dataset/labels/rev01/10.cache... 18324 images, 1796 backgrounds, 0 corrupt: 100%|██████████| 20120/20120 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning ../Dataset/labels/rev01/40... 2348 images, 248 backgrounds, 0 corrupt: 100%|██████████| 2596/2596 [00:01<00:00, 1874.98it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: ../Dataset/labels/rev01/40.cache\n",
      "Plotting labels to runs/detect/train16/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000526, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train16\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/3      3.01G     0.9144      2.354      1.065         30        640: 100%|██████████| 1258/1258 [02:22<00:00,  8.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 82/82 [00:13<00:00,  6.02it/s]\n",
      "                   all       2596       3557      0.599      0.589      0.557      0.444\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/3      3.03G     0.8406      1.349      1.031         26        640: 100%|██████████| 1258/1258 [02:13<00:00,  9.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 82/82 [00:13<00:00,  5.94it/s]\n",
      "                   all       2596       3557      0.691      0.575      0.641      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/3      3.32G     0.7837      1.041      1.006         23        640: 100%|██████████| 1258/1258 [03:30<00:00,  5.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  57%|█████▋    | 47/82 [00:21<00:24,  1.45it/s]"
     ]
    }
   ],
   "source": [
    "# Train the model using the 'coco128.yaml' dataset for 3 epochs\n",
    "results = model.train(data=DATASET_YAML, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''# Evaluate the model's performance on the validation set\n",
    "results = model.val()\n",
    "\n",
    "# Perform object detection on an image using the model\n",
    "results = model('https://ultralytics.com/images/bus.jpg')\n",
    "\n",
    "# Export the model to ONNX format\n",
    "success = model.export(format='onnx')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from constants import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../\" + TEST_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dataset/images/rev01/26/26_20201031 (2308).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201031 (2939).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201031 (2941).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201031 (2949).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201101 (3156).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201101 (3172).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201101 (3448).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201101 (3449).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201101 (3482).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201101 (3737).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201101 (4455).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201102 (7007).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201109 (10141).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201111 (12731).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201111 (13500).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201111 (13713).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201111 (13715).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201111 (13714).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201111 (14454).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201112 (14837).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201112 (15426).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201112 (16043).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201113 (17480).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201117 (18808).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201117 (18832).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201117 (18831).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201117 (18841).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201117 (18843).JPG',\n",
       " 'Dataset/images/rev01/26/26_20201117 (18851).JPG',\n",
       " 'Dataset/images/rev02/26/26_20201121 (392).JPG',\n",
       " 'Dataset/images/rev02/26/26_20201122 (529).JPG',\n",
       " 'Dataset/images/rev20/66/66_20220611 (9).JPG',\n",
       " 'Dataset/images/rev20/66/66_20220722 (143).JPG',\n",
       " 'Dataset/images/rev20/66/66_20220722 (145).JPG',\n",
       " 'Dataset/images/rev20/59/59_20220613 (8).JPG',\n",
       " 'Dataset/images/rev20/59/59_20220613 (11).JPG',\n",
       " 'Dataset/images/rev20/59/59_20220722 (70).JPG',\n",
       " 'Dataset/images/rev20/59/59_20220722 (74).JPG',\n",
       " 'Dataset/images/rev20/59/59_20220722 (80).JPG',\n",
       " 'Dataset/images/rev21/66/66_20220722 (6).JPG',\n",
       " 'Dataset/images/rev21/66/66_20220904 (60).JPG',\n",
       " 'Dataset/images/rev21/66/66_20220912 (89).JPG',\n",
       " 'Dataset/images/rev21/59/59_20220914 (35).JPG',\n",
       " 'Dataset/images/rev21/59/59_20220914 (36).JPG',\n",
       " 'Dataset/images/rev21/59/59_20220914 (39).JPG',\n",
       " 'Dataset/images/rev22/66/66_20220914 (5).JPG',\n",
       " 'Dataset/images/rev22/66/66_20220928 (30).JPG',\n",
       " 'Dataset/images/rev22/66/66_20221124 (177).JPG',\n",
       " 'Dataset/images/rev22/59/59_20220914 (5).JPG',\n",
       " 'Dataset/images/rev22/59/59_20221106 (85).JPG',\n",
       " 'Dataset/images/rev22/59/59_20221124 (94).JPG',\n",
       " 'Dataset/images/rev23/66/66_20230118 (52).JPG',\n",
       " 'Dataset/images/rev23/66/66_20230118 (54).JPG',\n",
       " 'Dataset/images/rev23/59/59_20221124 (7).JPG',\n",
       " 'Dataset/images/rev23/59/59_20221124 (9).JPG',\n",
       " 'Dataset/images/rev23/59/59_20230118 (122).JPG',\n",
       " 'Dataset/images/rev24/66/66_20230118 (1).JPG',\n",
       " 'Dataset/images/rev24/66/66_20230315 (146).JPG',\n",
       " 'Dataset/images/rev24/59/59_20230118 (5).JPG',\n",
       " 'Dataset/images/rev24/59/59_20230315 (82).JPG',\n",
       " 'Dataset/images/rev17/48/48_20220216 (5).JPG',\n",
       " 'Dataset/images/rev17/48/48_20220216 (3).JPG',\n",
       " 'Dataset/images/rev17/48/48_20220221 (9).JPG',\n",
       " 'Dataset/images/rev17/48/48_20220301 (117).JPG',\n",
       " 'Dataset/images/rev17/48/48_20220301 (119).JPG',\n",
       " 'Dataset/images/rev17/48/48_20220304 (139).JPG',\n",
       " 'Dataset/images/rev17/48/48_20220304 (137).JPG',\n",
       " 'Dataset/images/rev17/48/48_20220304 (160).JPG',\n",
       " 'Dataset/images/rev17/48/48_20220304 (166).JPG',\n",
       " 'Dataset/images/rev17/48/48_20220304 (172).JPG',\n",
       " 'Dataset/images/rev17/48/48_20220304 (174).JPG',\n",
       " 'Dataset/images/rev17/48/48_20220308 (193).JPG',\n",
       " 'Dataset/images/rev17/48/48_20220308 (196).JPG',\n",
       " 'Dataset/images/rev17/48/48_20220325 (313).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220216 (24).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220216 (21).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220216 (26).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220216 (30).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220216 (40).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220217 (52).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220219 (109).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220219 (140).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220219 (144).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220224 (328).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220304 (526).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220306 (629).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220308 (806).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220308 (829).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220308 (827).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220308 (830).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220310 (874).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220318 (1120).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220318 (1124).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220318 (1121).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220320 (1171).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220321 (1315).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220322 (1361).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220322 (1400).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220322 (1407).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220325 (1563).JPG',\n",
       " 'Dataset/images/rev17/49/49_20220327 (1866).JPG',\n",
       " 'Dataset/images/rev17/47/47_20220216 (3).JPG',\n",
       " 'Dataset/images/rev17/47/47_20220216 (1).JPG',\n",
       " 'Dataset/images/rev17/47/47_20220220 (60).JPG',\n",
       " 'Dataset/images/rev17/47/47_20220222 (104).JPG',\n",
       " 'Dataset/images/rev17/47/47_20220312 (279).JPG',\n",
       " 'Dataset/images/rev17/47/47_20220319 (333).JPG',\n",
       " 'Dataset/images/rev17/47/47_20220322 (429).JPG',\n",
       " 'Dataset/images/rev17/47/47_20220322 (437).JPG',\n",
       " 'Dataset/images/rev17/47/47_20220322 (440).JPG',\n",
       " 'Dataset/images/rev17/47/47_20220322 (443).JPG',\n",
       " 'Dataset/images/rev17/47/47_20220326 (484).JPG',\n",
       " 'Dataset/images/rev17/47/47_20220330 (658).JPG',\n",
       " 'Dataset/images/rev17/47/47_20220401 (792).JPG',\n",
       " 'Dataset/images/rev17/8/8_20220322 (488).JPG',\n",
       " 'Dataset/images/rev17/8/8_20220331 (596).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220216 (1).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220219 (62).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220219 (61).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220219 (136).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220223 (313).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220226 (669).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220228 (1107).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220302 (1173).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220302 (1328).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220302 (1322).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220304 (1366).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220306 (1436).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220314 (1848).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220315 (2098).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220317 (2272).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220318 (2294).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220318 (2293).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220320 (2344).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220323 (2509).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220323 (2520).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220323 (2519).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220325 (2725).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220325 (2723).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220325 (2731).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220325 (2730).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220326 (3447).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220328 (3563).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220328 (3559).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220328 (3573).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220328 (3570).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220328 (3569).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220328 (3576).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220328 (3575).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220331 (4319).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220331 (4324).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220331 (4344).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220401 (4376).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220401 (4371).JPG',\n",
       " 'Dataset/images/rev17/9/9_20220401 (4375).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220331 (9).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220402 (133).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220403 (216).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220406 (410).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220406 (414).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220406 (445).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220406 (555).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220406 (553).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220406 (560).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220406 (559).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220406 (626).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220406 (711).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220406 (739).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220407 (798).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220409 (958).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220409 (1012).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220409 (1019).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220409 (1027).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220411 (1248).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220412 (1443).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220413 (1529).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220414 (1677).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220417 (2010).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220417 (2164).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220418 (2249).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220419 (2402).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220419 (2527).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220419 (2574).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220419 (2576).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220420 (2616).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220420 (2622).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220420 (2647).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220423 (2728).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220424 (2841).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220426 (3001).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220426 (3002).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220426 (3003).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220426 (3019).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220427 (3140).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220427 (3139).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220427 (3143).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220427 (3274).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220427 (3275).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220427 (3276).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220428 (3304).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220428 (3301).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220428 (3306).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220428 (3351).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220429 (3648).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220429 (3865).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220501 (7575).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220502 (8182).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220502 (10575).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220504 (11013).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220504 (11205).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220506 (12242).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220507 (12733).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220510 (13898).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220511 (14388).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220512 (15947).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220512 (16152).JPG',\n",
       " 'Dataset/images/rev18/10/10_20220512 (16324).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220405 (330).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220410 (568).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220410 (569).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220413 (773).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220413 (777).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220417 (940).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220418 (995).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220419 (1538).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220420 (1582).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220420 (1718).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220426 (2428).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220428 (2630).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220428 (2762).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220501 (2874).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220501 (2884).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220501 (2878).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220502 (2978).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220502 (3287).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220502 (3473).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220503 (3570).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220504 (3585).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220504 (3632).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220504 (3628).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220504 (3630).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220506 (3766).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220507 (3909).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220510 (4311).JPG',\n",
       " 'Dataset/images/rev18/11/11_20220510 (4307).JPG',\n",
       " 'Dataset/images/rev18/45/45_20220401 (1).JPG',\n",
       " 'Dataset/images/rev18/45/45_20220401 (10).JPG',\n",
       " 'Dataset/images/rev18/45/45_20220425 (166).JPG',\n",
       " 'Dataset/images/rev18/45/45_20220510 (281).JPG',\n",
       " 'Dataset/images/rev18/44/44_20220428 (218).JPG',\n",
       " 'Dataset/images/rev18/44/44_20220509 (349).JPG',\n",
       " 'Dataset/images/rev18/44/44_20220510 (380).JPG',\n",
       " 'Dataset/images/rev18/46/46_20220421 (327).JPG',\n",
       " 'Dataset/images/rev18/46/46_20220422 (333).JPG',\n",
       " 'Dataset/images/rev18/46/46_20220510 (990).JPG',\n",
       " 'Dataset/images/rev18/16/16_20220401 (6).JPG',\n",
       " 'Dataset/images/rev18/16/16_20220428 (385).JPG',\n",
       " 'Dataset/images/rev18/16/16_20220510 (838).JPG',\n",
       " 'Dataset/images/rev18/18/18_20220331 (1).JPG',\n",
       " 'Dataset/images/rev18/18/18_20220331 (11).JPG',\n",
       " 'Dataset/images/rev18/18/18_20220331 (52).JPG',\n",
       " 'Dataset/images/rev18/18/18_20220402 (186).JPG',\n",
       " 'Dataset/images/rev18/18/18_20220403 (207).JPG',\n",
       " 'Dataset/images/rev18/18/18_20220412 (500).JPG',\n",
       " 'Dataset/images/rev18/18/18_20220412 (499).JPG',\n",
       " 'Dataset/images/rev18/18/18_20220412 (501).JPG',\n",
       " 'Dataset/images/rev18/18/18_20220427 (1000).JPG',\n",
       " 'Dataset/images/rev18/18/18_20220428 (1014).JPG',\n",
       " 'Dataset/images/rev18/18/18_20220508 (1734).JPG',\n",
       " 'Dataset/images/rev18/18/18_20220511 (4943).JPG',\n",
       " 'Dataset/images/rev18/18/18_20220512 (5236).JPG',\n",
       " 'Dataset/images/rev18/19/19_20220331 (1).JPG',\n",
       " 'Dataset/images/rev18/19/19_20220404 (440).JPG',\n",
       " 'Dataset/images/rev18/19/19_20220406 (464).JPG',\n",
       " 'Dataset/images/rev18/19/19_20220414 (749).JPG',\n",
       " 'Dataset/images/rev18/19/19_20220417 (875).JPG',\n",
       " 'Dataset/images/rev18/19/19_20220418 (1082).JPG',\n",
       " 'Dataset/images/rev18/19/19_20220418 (1174).JPG',\n",
       " 'Dataset/images/rev18/19/19_20220419 (1336).JPG',\n",
       " 'Dataset/images/rev18/19/19_20220419 (1471).JPG',\n",
       " 'Dataset/images/rev18/19/19_20220420 (2386).JPG',\n",
       " 'Dataset/images/rev18/19/19_20220421 (2965).JPG',\n",
       " 'Dataset/images/rev18/19/19_20220421 (3067).JPG',\n",
       " 'Dataset/images/rev18/19/19_20220422 (3124).JPG',\n",
       " 'Dataset/images/rev18/19/19_20220423 (3169).JPG',\n",
       " 'Dataset/images/rev18/19/19_20220425 (3241).JPG',\n",
       " 'Dataset/images/rev18/19/19_20220429 (3976).JPG',\n",
       " 'Dataset/images/rev18/19/19_20220502 (4696).JPG',\n",
       " 'Dataset/images/rev18/19/19_20220504 (5011).JPG',\n",
       " 'Dataset/images/rev18/19/19_20220506 (5065).JPG',\n",
       " 'Dataset/images/rev18/19/19_20220511 (5345).JPG',\n",
       " 'Dataset/images/rev18/19/19_20220511 (5439).JPG',\n",
       " 'Dataset/images/rev18/19/19_20220512 (5508).JPG',\n",
       " 'Dataset/images/rev18/20/20_20220331 (3).JPG',\n",
       " 'Dataset/images/rev18/20/20_20220331 (5).JPG',\n",
       " 'Dataset/images/rev18/20/20_20220401 (23).JPG',\n",
       " 'Dataset/images/rev18/20/20_20220403 (180).JPG',\n",
       " 'Dataset/images/rev18/20/20_20220403 (207).JPG',\n",
       " 'Dataset/images/rev18/20/20_20220405 (272).JPG',\n",
       " 'Dataset/images/rev18/20/20_20220406 (419).JPG',\n",
       " 'Dataset/images/rev18/20/20_20220409 (605).JPG',\n",
       " 'Dataset/images/rev18/20/20_20220415 (1056).JPG',\n",
       " 'Dataset/images/rev18/20/20_20220416 (1113).JPG',\n",
       " 'Dataset/images/rev18/20/20_20220416 (1118).JPG',\n",
       " 'Dataset/images/rev18/20/20_20220416 (1142).JPG',\n",
       " 'Dataset/images/rev18/20/20_20220419 (1514).JPG',\n",
       " 'Dataset/images/rev18/20/20_20220430 (2094).JPG',\n",
       " 'Dataset/images/rev18/22/22_20220330 (1).JPG',\n",
       " 'Dataset/images/rev18/22/22_20220330 (9).JPG',\n",
       " 'Dataset/images/rev18/22/22_20220408 (909).JPG',\n",
       " 'Dataset/images/rev18/22/22_20220410 (985).JPG',\n",
       " 'Dataset/images/rev18/22/22_20220416 (1660).JPG',\n",
       " 'Dataset/images/rev18/22/22_20220418 (1720).JPG',\n",
       " 'Dataset/images/rev18/22/22_20220421 (2197).JPG',\n",
       " 'Dataset/images/rev18/22/22_20220425 (2395).JPG',\n",
       " 'Dataset/images/rev18/22/22_20220428 (2803).JPG',\n",
       " 'Dataset/images/rev18/22/22_20220502 (3072).JPG',\n",
       " 'Dataset/images/rev18/22/22_20220502 (3123).JPG',\n",
       " 'Dataset/images/rev18/22/22_20220510 (3527).JPG',\n",
       " 'Dataset/images/rev18/1/1_20220402 (175).JPG',\n",
       " 'Dataset/images/rev18/1/1_20220402 (1231).JPG',\n",
       " 'Dataset/images/rev18/1/1_20220403 (1521).JPG',\n",
       " 'Dataset/images/rev18/1/1_20220404 (1573).JPG',\n",
       " 'Dataset/images/rev18/1/1_20220410 (2263).JPG',\n",
       " 'Dataset/images/rev18/1/1_20220413 (2343).JPG',\n",
       " 'Dataset/images/rev18/1/1_20220413 (2361).JPG',\n",
       " 'Dataset/images/rev18/1/1_20220420 (3055).JPG',\n",
       " 'Dataset/images/rev18/1/1_20220420 (3151).JPG',\n",
       " 'Dataset/images/rev18/1/1_20220420 (3239).JPG',\n",
       " 'Dataset/images/rev18/1/1_20220425 (3338).JPG',\n",
       " 'Dataset/images/rev18/1/1_20220428 (3457).JPG',\n",
       " 'Dataset/images/rev18/1/1_20220503 (3614).JPG',\n",
       " 'Dataset/images/rev18/1/1_20220512 (3851).JPG',\n",
       " 'Dataset/images/rev18/24/24_20220331 (188).JPG',\n",
       " 'Dataset/images/rev18/24/24_20220402 (1363).JPG',\n",
       " 'Dataset/images/rev18/24/24_20220403 (1513).JPG',\n",
       " 'Dataset/images/rev18/24/24_20220406 (1697).JPG',\n",
       " 'Dataset/images/rev18/24/24_20220406 (1695).JPG',\n",
       " 'Dataset/images/rev18/24/24_20220406 (1702).JPG',\n",
       " 'Dataset/images/rev18/24/24_20220407 (1716).JPG',\n",
       " 'Dataset/images/rev18/24/24_20220409 (2312).JPG',\n",
       " 'Dataset/images/rev18/24/24_20220410 (2360).JPG',\n",
       " 'Dataset/images/rev18/24/24_20220420 (3818).JPG',\n",
       " 'Dataset/images/rev18/24/24_20220421 (4150).JPG',\n",
       " 'Dataset/images/rev18/24/24_20220423 (4619).JPG',\n",
       " 'Dataset/images/rev18/24/24_20220425 (4681).JPG',\n",
       " 'Dataset/images/rev18/24/24_20220510 (5964).JPG',\n",
       " 'Dataset/images/rev18/24/24_20220512 (6133).JPG',\n",
       " 'Dataset/images/rev18/25/25_20220401 (42).JPG',\n",
       " 'Dataset/images/rev18/25/25_20220401 (54).JPG',\n",
       " 'Dataset/images/rev18/25/25_20220402 (261).JPG',\n",
       " 'Dataset/images/rev18/25/25_20220402 (323).JPG',\n",
       " 'Dataset/images/rev18/25/25_20220402 (402).JPG',\n",
       " 'Dataset/images/rev18/25/25_20220402 (592).JPG',\n",
       " 'Dataset/images/rev18/25/25_20220407 (844).JPG',\n",
       " 'Dataset/images/rev18/25/25_20220409 (869).JPG',\n",
       " 'Dataset/images/rev18/25/25_20220502 (2813).JPG',\n",
       " 'Dataset/images/rev18/3/3_20220330 (3).JPG',\n",
       " 'Dataset/images/rev18/3/3_20220407 (161).JPG',\n",
       " 'Dataset/images/rev18/3/3_20220410 (208).JPG',\n",
       " 'Dataset/images/rev18/3/3_20220413 (283).JPG',\n",
       " 'Dataset/images/rev18/3/3_20220416 (432).JPG',\n",
       " 'Dataset/images/rev18/3/3_20220419 (568).JPG',\n",
       " 'Dataset/images/rev18/3/3_20220502 (991).JPG',\n",
       " 'Dataset/images/rev18/3/3_20220502 (1071).JPG',\n",
       " 'Dataset/images/rev18/3/3_20220510 (1239).JPG',\n",
       " 'Dataset/images/rev18/3/3_20220510 (1236).JPG',\n",
       " 'Dataset/images/rev18/28/28_20220330 (9).JPG',\n",
       " 'Dataset/images/rev18/28/28_20220331 (53).JPG',\n",
       " 'Dataset/images/rev18/28/28_20220403 (2353).JPG',\n",
       " 'Dataset/images/rev18/28/28_20220403 (2482).JPG',\n",
       " 'Dataset/images/rev18/28/28_20220406 (2551).JPG',\n",
       " 'Dataset/images/rev18/28/28_20220408 (2673).JPG',\n",
       " 'Dataset/images/rev18/28/28_20220413 (2970).JPG',\n",
       " 'Dataset/images/rev18/28/28_20220417 (3057).JPG',\n",
       " 'Dataset/images/rev18/28/28_20220421 (3857).JPG',\n",
       " 'Dataset/images/rev18/28/28_20220501 (4041).JPG',\n",
       " 'Dataset/images/rev18/28/28_20220512 (4423).JPG',\n",
       " 'Dataset/images/rev18/28/28_20220512 (4456).JPG',\n",
       " 'Dataset/images/rev18/28/28_20220512 (4448).JPG',\n",
       " 'Dataset/images/rev18/28/28_20220512 (4487).JPG',\n",
       " 'Dataset/images/rev18/5/5_20220402 (116).JPG',\n",
       " 'Dataset/images/rev18/5/5_20220402 (172).JPG',\n",
       " 'Dataset/images/rev18/5/5_20220402 (178).JPG',\n",
       " 'Dataset/images/rev18/5/5_20220402 (185).JPG',\n",
       " 'Dataset/images/rev18/5/5_20220403 (351).JPG',\n",
       " 'Dataset/images/rev18/5/5_20220410 (618).JPG',\n",
       " 'Dataset/images/rev18/5/5_20220410 (620).JPG',\n",
       " 'Dataset/images/rev18/5/5_20220412 (727).JPG',\n",
       " 'Dataset/images/rev18/5/5_20220413 (785).JPG',\n",
       " 'Dataset/images/rev18/5/5_20220512 (1999).JPG',\n",
       " 'Dataset/images/rev18/2/2_20220401 (71).JPG',\n",
       " 'Dataset/images/rev18/2/2_20220401 (197).JPG',\n",
       " 'Dataset/images/rev18/2/2_20220401 (328).JPG',\n",
       " 'Dataset/images/rev18/2/2_20220401 (465).JPG',\n",
       " 'Dataset/images/rev18/2/2_20220403 (1109).JPG',\n",
       " 'Dataset/images/rev18/2/2_20220404 (1313).JPG',\n",
       " 'Dataset/images/rev18/2/2_20220404 (1312).JPG',\n",
       " 'Dataset/images/rev18/2/2_20220409 (1527).JPG',\n",
       " 'Dataset/images/rev18/2/2_20220419 (1974).JPG',\n",
       " 'Dataset/images/rev18/2/2_20220423 (2271).JPG',\n",
       " 'Dataset/images/rev18/2/2_20220423 (2270).JPG',\n",
       " 'Dataset/images/rev18/2/2_20220424 (2340).JPG',\n",
       " 'Dataset/images/rev18/2/2_20220424 (2546).JPG',\n",
       " 'Dataset/images/rev18/31/31_20220330 (3).JPG',\n",
       " 'Dataset/images/rev18/31/31_20220512 (393).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220330 (9).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220403 (2334).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220403 (2377).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220406 (2722).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220406 (2761).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220408 (3255).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220409 (3679).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220409 (3731).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220410 (4741).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220413 (4963).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220414 (5160).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220414 (5494).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220415 (5589).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220415 (5772).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220416 (6197).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220421 (9245).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220423 (10486).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220425 (11253).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220425 (11484).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220426 (11858).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220426 (12049).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220428 (13301).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220430 (13925).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220430 (14157).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220502 (14813).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220503 (15492).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220503 (15614).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220504 (15633).JPG',\n",
       " 'Dataset/images/rev18/32/32_20220508 (15799).JPG',\n",
       " 'Dataset/images/rev18/33/33_20220404 (24).JPG',\n",
       " 'Dataset/images/rev18/33/33_20220409 (152).JPG',\n",
       " 'Dataset/images/rev18/33/33_20220420 (232).JPG',\n",
       " 'Dataset/images/rev18/33/33_20220428 (253).JPG',\n",
       " 'Dataset/images/rev18/33/33_20220428 (257).JPG',\n",
       " 'Dataset/images/rev18/33/33_20220507 (349).JPG',\n",
       " 'Dataset/images/rev18/33/33_20220507 (883).JPG',\n",
       " 'Dataset/images/rev18/33/33_20220508 (946).JPG',\n",
       " 'Dataset/images/rev18/33/33_20220509 (959).JPG',\n",
       " 'Dataset/images/rev18/33/33_20220509 (955).JPG',\n",
       " 'Dataset/images/rev18/33/33_20220510 (972).JPG',\n",
       " 'Dataset/images/rev18/33/33_20220510 (976).JPG',\n",
       " 'Dataset/images/rev18/50/50_20220331 (23).JPG',\n",
       " 'Dataset/images/rev18/50/50_20220331 (17).JPG',\n",
       " 'Dataset/images/rev18/50/50_20220331 (28).JPG',\n",
       " 'Dataset/images/rev18/50/50_20220331 (34).JPG',\n",
       " 'Dataset/images/rev18/50/50_20220409 (1548).JPG',\n",
       " 'Dataset/images/rev18/50/50_20220413 (2190).JPG',\n",
       " 'Dataset/images/rev18/50/50_20220414 (2207).JPG',\n",
       " 'Dataset/images/rev18/35/35_20220330 (11).JPG',\n",
       " 'Dataset/images/rev18/35/35_20220330 (8).JPG',\n",
       " 'Dataset/images/rev18/35/35_20220402 (182).JPG',\n",
       " 'Dataset/images/rev18/35/35_20220405 (266).JPG',\n",
       " 'Dataset/images/rev18/35/35_20220428 (812).JPG',\n",
       " 'Dataset/images/rev18/35/35_20220428 (818).JPG',\n",
       " 'Dataset/images/rev18/35/35_20220430 (1003).JPG',\n",
       " 'Dataset/images/rev18/36/36_20220331 (5).JPG',\n",
       " 'Dataset/images/rev18/36/36_20220331 (1).JPG',\n",
       " 'Dataset/images/rev18/36/36_20220401 (37).JPG',\n",
       " 'Dataset/images/rev18/36/36_20220406 (336).JPG',\n",
       " 'Dataset/images/rev18/36/36_20220420 (694).JPG',\n",
       " 'Dataset/images/rev18/36/36_20220420 (803).JPG',\n",
       " 'Dataset/images/rev18/36/36_20220420 (799).JPG',\n",
       " 'Dataset/images/rev18/36/36_20220507 (1218).JPG',\n",
       " 'Dataset/images/rev18/38/38_20220412 (1303).JPG',\n",
       " 'Dataset/images/rev18/38/38_20220422 (1739).JPG',\n",
       " 'Dataset/images/rev18/38/38_20220507 (2240).JPG',\n",
       " 'Dataset/images/rev18/38/38_20220507 (2257).JPG',\n",
       " 'Dataset/images/rev18/38/38_20220511 (2383).JPG',\n",
       " 'Dataset/images/rev18/38/38_20220512 (2397).JPG',\n",
       " 'Dataset/images/rev18/38/38_20220512 (2400).JPG',\n",
       " 'Dataset/images/rev18/39/39_20220331 (3566).JPG',\n",
       " 'Dataset/images/rev18/39/39_20220401 (4227).JPG',\n",
       " 'Dataset/images/rev18/39/39_20220401 (4261).JPG',\n",
       " 'Dataset/images/rev18/39/39_20220401 (5897).JPG',\n",
       " 'Dataset/images/rev18/39/39_20220403 (11975).JPG',\n",
       " 'Dataset/images/rev18/39/39_20220404 (12251).JPG',\n",
       " 'Dataset/images/rev18/39/39_20220406 (12424).JPG',\n",
       " 'Dataset/images/rev18/39/39_20220407 (12728).JPG',\n",
       " 'Dataset/images/rev18/39/39_20220412 (14623).JPG',\n",
       " 'Dataset/images/rev18/39/39_20220418 (15408).JPG',\n",
       " 'Dataset/images/rev18/41/41_20220401 (14).JPG',\n",
       " 'Dataset/images/rev18/41/41_20220401 (1).JPG',\n",
       " 'Dataset/images/rev18/41/41_20220401 (18).JPG',\n",
       " 'Dataset/images/rev18/41/41_20220408 (294).JPG',\n",
       " 'Dataset/images/rev18/41/41_20220414 (382).JPG',\n",
       " 'Dataset/images/rev18/41/41_20220419 (499).JPG',\n",
       " 'Dataset/images/rev18/42/42_20220401 (18).JPG',\n",
       " 'Dataset/images/rev18/42/42_20220401 (14).JPG',\n",
       " 'Dataset/images/rev18/42/42_20220510 (70).JPG',\n",
       " 'Dataset/images/rev18/48/48_20220403 (29).JPG',\n",
       " 'Dataset/images/rev18/48/48_20220405 (47).JPG',\n",
       " 'Dataset/images/rev18/48/48_20220510 (178).JPG',\n",
       " 'Dataset/images/rev18/49/49_20220330 (1).JPG',\n",
       " 'Dataset/images/rev18/49/49_20220404 (696).JPG',\n",
       " 'Dataset/images/rev18/49/49_20220404 (702).JPG',\n",
       " 'Dataset/images/rev18/49/49_20220407 (895).JPG',\n",
       " 'Dataset/images/rev18/49/49_20220407 (907).JPG',\n",
       " 'Dataset/images/rev18/49/49_20220408 (937).JPG',\n",
       " 'Dataset/images/rev18/49/49_20220412 (1244).JPG',\n",
       " 'Dataset/images/rev18/49/49_20220412 (1247).JPG',\n",
       " 'Dataset/images/rev18/49/49_20220414 (1411).JPG',\n",
       " 'Dataset/images/rev18/49/49_20220417 (1435).JPG',\n",
       " 'Dataset/images/rev18/49/49_20220417 (1436).JPG',\n",
       " 'Dataset/images/rev18/49/49_20220420 (1830).JPG',\n",
       " 'Dataset/images/rev18/49/49_20220422 (2456).JPG',\n",
       " 'Dataset/images/rev18/49/49_20220424 (2492).JPG',\n",
       " 'Dataset/images/rev18/49/49_20220428 (2742).JPG',\n",
       " 'Dataset/images/rev18/49/49_20220428 (2778).JPG',\n",
       " 'Dataset/images/rev18/49/49_20220429 (2791).JPG',\n",
       " 'Dataset/images/rev18/49/49_20220501 (2960).JPG',\n",
       " 'Dataset/images/rev18/49/49_20220502 (3030).JPG',\n",
       " 'Dataset/images/rev18/49/49_20220506 (3265).JPG',\n",
       " 'Dataset/images/rev18/49/49_20220506 (3266).JPG',\n",
       " 'Dataset/images/rev18/49/49_20220507 (3345).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220401 (20).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220402 (197).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220404 (295).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220404 (301).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220405 (376).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220405 (375).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220406 (466).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220409 (560).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220409 (568).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220409 (581).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220410 (885).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220412 (982).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220415 (1198).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220416 (1262).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220417 (1294).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220418 (1363).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220421 (1748).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220421 (1759).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220421 (1877).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220427 (2105).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220428 (2163).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220428 (2175).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220429 (2270).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220429 (2295).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220501 (2371).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220503 (2472).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220503 (2524).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220503 (2529).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220503 (2570).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220505 (2619).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220507 (2770).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220510 (2839).JPG',\n",
       " 'Dataset/images/rev18/47/47_20220510 (2843).JPG',\n",
       " 'Dataset/images/rev18/8/8_20220417 (114).JPG',\n",
       " 'Dataset/images/rev18/8/8_20220512 (306).JPG',\n",
       " 'Dataset/images/rev18/8/8_20220512 (312).JPG',\n",
       " 'Dataset/images/rev18/9/9_20220401 (1).JPG',\n",
       " 'Dataset/images/rev18/9/9_20220401 (8).JPG',\n",
       " 'Dataset/images/rev18/9/9_20220401 (39).JPG',\n",
       " 'Dataset/images/rev18/9/9_20220401 (43).JPG',\n",
       " 'Dataset/images/rev18/9/9_20220401 (49).JPG',\n",
       " 'Dataset/images/rev18/9/9_20220402 (103).JPG',\n",
       " 'Dataset/images/rev18/9/9_20220402 (105).JPG',\n",
       " 'Dataset/images/rev18/9/9_20220403 (459).JPG',\n",
       " 'Dataset/images/rev18/9/9_20220403 (461).JPG',\n",
       " 'Dataset/images/rev18/9/9_20220408 (652).JPG',\n",
       " 'Dataset/images/rev18/9/9_20220410 (661).JPG',\n",
       " 'Dataset/images/rev18/9/9_20220410 (667).JPG',\n",
       " 'Dataset/images/rev18/9/9_20220410 (668).JPG',\n",
       " 'Dataset/images/rev18/9/9_20220417 (1103).JPG',\n",
       " 'Dataset/images/rev18/9/9_20220503 (1812).JPG',\n",
       " 'Dataset/images/rev18/9/9_20220510 (2898).JPG',\n",
       " 'Dataset/images/rev19/10/10_20220512 (15).JPG',\n",
       " 'Dataset/images/rev19/10/10_20220513 (610).JPG',\n",
       " 'Dataset/images/rev19/10/10_20220515 (967).JPG',\n",
       " 'Dataset/images/rev19/10/10_20220521 (2644).JPG',\n",
       " 'Dataset/images/rev19/10/10_20220527 (14052).JPG',\n",
       " 'Dataset/images/rev19/10/10_20220527 (15176).JPG',\n",
       " 'Dataset/images/rev19/10/10_20220531 (17119).JPG',\n",
       " 'Dataset/images/rev19/10/10_20220601 (17377).JPG',\n",
       " 'Dataset/images/rev19/10/10_20220601 (17448).JPG',\n",
       " 'Dataset/images/rev19/10/10_20220603 (18343).JPG',\n",
       " 'Dataset/images/rev19/10/10_20220603 (20322).JPG',\n",
       " 'Dataset/images/rev19/10/10_20220604 (20654).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220510 (10).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220510 (19).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220511 (174).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220514 (676).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220516 (1095).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220517 (1206).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220518 (1355).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220518 (1356).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220519 (1401).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220522 (1634).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220522 (1632).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220523 (1666).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220524 (1908).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220524 (2389).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220527 (2785).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220527 (2816).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220601 (3422).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220602 (3501).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220603 (3749).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220603 (3754).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220604 (3811).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220605 (3958).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220605 (3965).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220605 (3995).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220607 (4270).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220608 (4590).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220608 (4659).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220609 (4780).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220610 (5033).JPG',\n",
       " 'Dataset/images/rev19/11/11_20220611 (5199).JPG',\n",
       " 'Dataset/images/rev19/45/45_20220510 (1).JPG',\n",
       " 'Dataset/images/rev19/44/44_20220512 (46).JPG',\n",
       " 'Dataset/images/rev19/44/44_20220613 (552).JPG',\n",
       " 'Dataset/images/rev19/46/46_20220512 (45).JPG',\n",
       " 'Dataset/images/rev19/46/46_20220513 (105).JPG',\n",
       " 'Dataset/images/rev19/46/46_20220517 (272).JPG',\n",
       " 'Dataset/images/rev19/46/46_20220521 (369).JPG',\n",
       " 'Dataset/images/rev19/46/46_20220525 (490).JPG',\n",
       " 'Dataset/images/rev19/46/46_20220528 (624).JPG',\n",
       " 'Dataset/images/rev19/46/46_20220603 (1165).JPG',\n",
       " 'Dataset/images/rev19/46/46_20220607 (1225).JPG',\n",
       " 'Dataset/images/rev19/46/46_20220607 (1243).JPG',\n",
       " 'Dataset/images/rev19/46/46_20220607 (1251).JPG',\n",
       " 'Dataset/images/rev19/46/46_20220608 (1273).JPG',\n",
       " 'Dataset/images/rev19/46/46_20220611 (1307).JPG',\n",
       " 'Dataset/images/rev19/16/16_20220603 (862).JPG',\n",
       " 'Dataset/images/rev19/16/16_20220603 (905).JPG',\n",
       " 'Dataset/images/rev19/16/16_20220611 (1149).JPG',\n",
       " 'Dataset/images/rev19/18/18_20220513 (66).JPG',\n",
       " 'Dataset/images/rev19/18/18_20220514 (136).JPG',\n",
       " 'Dataset/images/rev19/18/18_20220516 (277).JPG',\n",
       " 'Dataset/images/rev19/18/18_20220526 (4301).JPG',\n",
       " 'Dataset/images/rev19/18/18_20220528 (4605).JPG',\n",
       " 'Dataset/images/rev19/18/18_20220601 (5005).JPG',\n",
       " 'Dataset/images/rev19/18/18_20220604 (5202).JPG',\n",
       " 'Dataset/images/rev19/18/18_20220606 (5340).JPG',\n",
       " 'Dataset/images/rev19/18/18_20220608 (5724).JPG',\n",
       " 'Dataset/images/rev19/18/18_20220608 (6384).JPG',\n",
       " 'Dataset/images/rev19/19/19_20220512 (1).JPG',\n",
       " 'Dataset/images/rev19/19/19_20220514 (227).JPG',\n",
       " 'Dataset/images/rev19/19/19_20220518 (1306).JPG',\n",
       " 'Dataset/images/rev19/19/19_20220520 (1386).JPG',\n",
       " 'Dataset/images/rev19/19/19_20220521 (1661).JPG',\n",
       " 'Dataset/images/rev19/19/19_20220522 (1943).JPG',\n",
       " 'Dataset/images/rev19/19/19_20220523 (2070).JPG',\n",
       " 'Dataset/images/rev19/19/19_20220524 (2429).JPG',\n",
       " 'Dataset/images/rev19/19/19_20220524 (2998).JPG',\n",
       " 'Dataset/images/rev19/19/19_20220526 (3267).JPG',\n",
       " 'Dataset/images/rev19/19/19_20220526 (3282).JPG',\n",
       " 'Dataset/images/rev19/19/19_20220528 (3472).JPG',\n",
       " 'Dataset/images/rev19/19/19_20220530 (3830).JPG',\n",
       " 'Dataset/images/rev19/19/19_20220530 (3827).JPG',\n",
       " 'Dataset/images/rev19/19/19_20220530 (3976).JPG',\n",
       " 'Dataset/images/rev19/19/19_20220602 (4588).JPG',\n",
       " 'Dataset/images/rev19/19/19_20220603 (4905).JPG',\n",
       " 'Dataset/images/rev19/19/19_20220603 (4991).JPG',\n",
       " 'Dataset/images/rev19/19/19_20220603 (5015).JPG',\n",
       " 'Dataset/images/rev19/19/19_20220603 (5060).JPG',\n",
       " 'Dataset/images/rev19/19/19_20220606 (6145).JPG',\n",
       " 'Dataset/images/rev19/19/19_20220609 (7309).JPG',\n",
       " 'Dataset/images/rev19/19/19_20220610 (7429).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220510 (13).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220510 (20).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220510 (7).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220510 (33).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220512 (90).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220513 (752).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220513 (778).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220515 (1829).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220515 (1835).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220515 (2031).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220516 (2395).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220516 (2684).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220517 (3299).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220517 (3281).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220523 (4218).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220524 (4259).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220525 (4639).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220526 (4667).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220526 (4748).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220526 (4850).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220527 (5163).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220527 (5159).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220530 (5554).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220530 (5566).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220531 (5620).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220531 (5623).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220602 (5749).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220603 (5900).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220604 (6242).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220604 (6247).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220606 (6479).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220607 (6661).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220608 (6848).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220610 (7180).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220612 (7305).JPG',\n",
       " 'Dataset/images/rev19/21/21_20220613 (7331).JPG',\n",
       " 'Dataset/images/rev19/22/22_20220514 (775).JPG',\n",
       " 'Dataset/images/rev19/22/22_20220515 (908).JPG',\n",
       " 'Dataset/images/rev19/22/22_20220515 (965).JPG',\n",
       " 'Dataset/images/rev19/22/22_20220516 (1327).JPG',\n",
       " 'Dataset/images/rev19/22/22_20220518 (1740).JPG',\n",
       " 'Dataset/images/rev19/22/22_20220521 (1828).JPG',\n",
       " 'Dataset/images/rev19/22/22_20220522 (1886).JPG',\n",
       " 'Dataset/images/rev19/22/22_20220522 (1893).JPG',\n",
       " 'Dataset/images/rev19/22/22_20220523 (1976).JPG',\n",
       " 'Dataset/images/rev19/22/22_20220524 (2215).JPG',\n",
       " 'Dataset/images/rev19/22/22_20220524 (2228).JPG',\n",
       " 'Dataset/images/rev19/22/22_20220524 (2230).JPG',\n",
       " 'Dataset/images/rev19/22/22_20220527 (2444).JPG',\n",
       " 'Dataset/images/rev19/22/22_20220527 (2505).JPG',\n",
       " 'Dataset/images/rev19/22/22_20220529 (2998).JPG',\n",
       " 'Dataset/images/rev19/22/22_20220610 (4598).JPG',\n",
       " 'Dataset/images/rev19/22/22_20220610 (4703).JPG',\n",
       " 'Dataset/images/rev19/22/22_20220612 (4846).JPG',\n",
       " 'Dataset/images/rev19/22/22_20220612 (4937).JPG',\n",
       " 'Dataset/images/rev19/1/1_20220512 (5).JPG',\n",
       " 'Dataset/images/rev19/1/1_20220515 (127).JPG',\n",
       " 'Dataset/images/rev19/1/1_20220524 (347).JPG',\n",
       " 'Dataset/images/rev19/1/1_20220525 (506).JPG',\n",
       " 'Dataset/images/rev19/1/1_20220527 (599).JPG',\n",
       " 'Dataset/images/rev19/1/1_20220528 (663).JPG',\n",
       " 'Dataset/images/rev19/1/1_20220606 (1027).JPG',\n",
       " 'Dataset/images/rev19/1/1_20220610 (1166).JPG',\n",
       " 'Dataset/images/rev19/24/24_20220514 (298).JPG',\n",
       " 'Dataset/images/rev19/24/24_20220514 (380).JPG',\n",
       " 'Dataset/images/rev19/24/24_20220515 (488).JPG',\n",
       " 'Dataset/images/rev19/24/24_20220523 (1221).JPG',\n",
       " 'Dataset/images/rev19/24/24_20220523 (1263).JPG',\n",
       " 'Dataset/images/rev19/24/24_20220524 (1360).JPG',\n",
       " 'Dataset/images/rev19/24/24_20220528 (2696).JPG',\n",
       " 'Dataset/images/rev19/24/24_20220530 (2935).JPG',\n",
       " 'Dataset/images/rev19/24/24_20220531 (3085).JPG',\n",
       " 'Dataset/images/rev19/24/24_20220601 (3233).JPG',\n",
       " 'Dataset/images/rev19/24/24_20220601 (3273).JPG',\n",
       " 'Dataset/images/rev19/24/24_20220602 (3363).JPG',\n",
       " 'Dataset/images/rev19/24/24_20220603 (3492).JPG',\n",
       " 'Dataset/images/rev19/24/24_20220603 (3611).JPG',\n",
       " 'Dataset/images/rev19/24/24_20220604 (3805).JPG',\n",
       " 'Dataset/images/rev19/24/24_20220606 (4307).JPG',\n",
       " 'Dataset/images/rev19/24/24_20220607 (4731).JPG',\n",
       " 'Dataset/images/rev19/24/24_20220608 (4915).JPG',\n",
       " 'Dataset/images/rev19/24/24_20220609 (5059).JPG',\n",
       " 'Dataset/images/rev19/24/24_20220611 (5336).JPG',\n",
       " 'Dataset/images/rev19/25/25_20220512 (6).JPG',\n",
       " 'Dataset/images/rev19/25/25_20220512 (48).JPG',\n",
       " 'Dataset/images/rev19/25/25_20220517 (588).JPG',\n",
       " 'Dataset/images/rev19/25/25_20220517 (595).JPG',\n",
       " 'Dataset/images/rev19/25/25_20220519 (695).JPG',\n",
       " 'Dataset/images/rev19/25/25_20220529 (1704).JPG',\n",
       " 'Dataset/images/rev19/25/25_20220530 (1769).JPG',\n",
       " 'Dataset/images/rev19/25/25_20220603 (2068).JPG',\n",
       " 'Dataset/images/rev19/25/25_20220603 (2100).JPG',\n",
       " 'Dataset/images/rev19/25/25_20220604 (2296).JPG',\n",
       " 'Dataset/images/rev19/25/25_20220605 (2465).JPG',\n",
       " 'Dataset/images/rev19/25/25_20220606 (2669).JPG',\n",
       " 'Dataset/images/rev19/25/25_20220608 (2913).JPG',\n",
       " 'Dataset/images/rev19/25/25_20220608 (2945).JPG',\n",
       " 'Dataset/images/rev19/25/25_20220609 (3045).JPG',\n",
       " 'Dataset/images/rev19/25/25_20220610 (3152).JPG',\n",
       " 'Dataset/images/rev19/25/25_20220610 (3178).JPG',\n",
       " 'Dataset/images/rev19/28/28_20220512 (25).JPG',\n",
       " 'Dataset/images/rev19/28/28_20220525 (788).JPG',\n",
       " 'Dataset/images/rev19/28/28_20220525 (836).JPG',\n",
       " 'Dataset/images/rev19/28/28_20220528 (1632).JPG',\n",
       " 'Dataset/images/rev19/28/28_20220529 (1647).JPG',\n",
       " 'Dataset/images/rev19/28/28_20220531 (1768).JPG',\n",
       " 'Dataset/images/rev19/28/28_20220604 (1993).JPG',\n",
       " 'Dataset/images/rev19/28/28_20220604 (1994).JPG',\n",
       " 'Dataset/images/rev19/28/28_20220606 (2111).JPG',\n",
       " 'Dataset/images/rev19/28/28_20220612 (2829).JPG',\n",
       " 'Dataset/images/rev19/28/28_20220612 (2833).JPG',\n",
       " 'Dataset/images/rev19/5/5_20220512 (7).JPG',\n",
       " 'Dataset/images/rev19/5/5_20220516 (306).JPG',\n",
       " 'Dataset/images/rev19/5/5_20220610 (1205).JPG',\n",
       " 'Dataset/images/rev19/2/2_20220512 (18).JPG',\n",
       " 'Dataset/images/rev19/2/2_20220521 (1013).JPG',\n",
       " 'Dataset/images/rev19/2/2_20220521 (1057).JPG',\n",
       " 'Dataset/images/rev19/2/2_20220521 (1058).JPG',\n",
       " 'Dataset/images/rev19/2/2_20220524 (1400).JPG',\n",
       " 'Dataset/images/rev19/2/2_20220524 (1532).JPG',\n",
       " 'Dataset/images/rev19/2/2_20220610 (2443).JPG',\n",
       " 'Dataset/images/rev19/31/31_20220512 (16).JPG',\n",
       " 'Dataset/images/rev19/31/31_20220612 (311).JPG',\n",
       " 'Dataset/images/rev19/32/32_20220510 (7).JPG',\n",
       " 'Dataset/images/rev19/32/32_20220512 (788).JPG',\n",
       " 'Dataset/images/rev19/32/32_20220512 (830).JPG',\n",
       " 'Dataset/images/rev19/32/32_20220513 (2717).JPG',\n",
       " 'Dataset/images/rev19/32/32_20220514 (4165).JPG',\n",
       " 'Dataset/images/rev19/32/32_20220515 (5336).JPG',\n",
       " 'Dataset/images/rev19/32/32_20220516 (6684).JPG',\n",
       " 'Dataset/images/rev19/32/32_20220517 (6828).JPG',\n",
       " 'Dataset/images/rev19/32/32_20220517 (7831).JPG',\n",
       " 'Dataset/images/rev19/32/32_20220522 (11917).JPG',\n",
       " 'Dataset/images/rev19/32/32_20220524 (14016).JPG',\n",
       " 'Dataset/images/rev19/33/33_20220510 (14).JPG',\n",
       " 'Dataset/images/rev19/33/33_20220510 (21).JPG',\n",
       " 'Dataset/images/rev19/33/33_20220510 (1).JPG',\n",
       " 'Dataset/images/rev19/33/33_20220512 (38).JPG',\n",
       " 'Dataset/images/rev19/33/33_20220516 (58).JPG',\n",
       " 'Dataset/images/rev19/33/33_20220521 (137).JPG',\n",
       " 'Dataset/images/rev19/33/33_20220521 (153).JPG',\n",
       " 'Dataset/images/rev19/33/33_20220526 (223).JPG',\n",
       " 'Dataset/images/rev19/33/33_20220527 (241).JPG',\n",
       " 'Dataset/images/rev19/33/33_20220602 (265).JPG',\n",
       " 'Dataset/images/rev19/33/33_20220602 (262).JPG',\n",
       " 'Dataset/images/rev19/33/33_20220602 (267).JPG',\n",
       " 'Dataset/images/rev19/33/33_20220602 (268).JPG',\n",
       " 'Dataset/images/rev19/50/50_20220512 (1).JPG',\n",
       " 'Dataset/images/rev19/50/50_20220512 (15).JPG',\n",
       " 'Dataset/images/rev19/50/50_20220512 (156).JPG',\n",
       " 'Dataset/images/rev19/50/50_20220512 (264).JPG',\n",
       " 'Dataset/images/rev19/50/50_20220512 (2965).JPG',\n",
       " 'Dataset/images/rev19/50/50_20220515 (10646).JPG',\n",
       " 'Dataset/images/rev19/50/50_20220521 (21132).JPG',\n",
       " 'Dataset/images/rev19/50/50_20220521 (21143).JPG',\n",
       " 'Dataset/images/rev19/50/50_20220521 (21183).JPG',\n",
       " 'Dataset/images/rev19/50/50_20220522 (21344).JPG',\n",
       " 'Dataset/images/rev19/35/35_20220510 (13).JPG',\n",
       " 'Dataset/images/rev19/35/35_20220510 (1).JPG',\n",
       " 'Dataset/images/rev19/35/35_20220510 (24).JPG',\n",
       " 'Dataset/images/rev19/35/35_20220518 (868).JPG',\n",
       " 'Dataset/images/rev19/35/35_20220524 (1185).JPG',\n",
       " 'Dataset/images/rev19/35/35_20220531 (1438).JPG',\n",
       " 'Dataset/images/rev19/35/35_20220602 (1538).JPG',\n",
       " 'Dataset/images/rev19/35/35_20220602 (1537).JPG',\n",
       " 'Dataset/images/rev19/35/35_20220604 (2175).JPG',\n",
       " 'Dataset/images/rev19/35/35_20220609 (2386).JPG',\n",
       " 'Dataset/images/rev19/35/35_20220612 (2626).JPG',\n",
       " 'Dataset/images/rev19/36/36_20220607 (1076).JPG',\n",
       " 'Dataset/images/rev19/36/36_20220609 (1103).JPG',\n",
       " 'Dataset/images/rev19/36/36_20220610 (1224).JPG',\n",
       " 'Dataset/images/rev19/36/36_20220610 (1237).JPG',\n",
       " 'Dataset/images/rev19/38/38_20220512 (11).JPG',\n",
       " 'Dataset/images/rev19/38/38_20220512 (31).JPG',\n",
       " 'Dataset/images/rev19/38/38_20220512 (63).JPG',\n",
       " 'Dataset/images/rev19/38/38_20220527 (548).JPG',\n",
       " 'Dataset/images/rev19/38/38_20220606 (883).JPG',\n",
       " 'Dataset/images/rev19/38/38_20220610 (915).JPG',\n",
       " 'Dataset/images/rev19/39/39_20220515 (723).JPG',\n",
       " 'Dataset/images/rev19/39/39_20220516 (797).JPG',\n",
       " 'Dataset/images/rev19/39/39_20220517 (1331).JPG',\n",
       " 'Dataset/images/rev19/39/39_20220523 (2155).JPG',\n",
       " 'Dataset/images/rev19/39/39_20220524 (5557).JPG',\n",
       " 'Dataset/images/rev19/39/39_20220527 (5916).JPG',\n",
       " 'Dataset/images/rev19/39/39_20220527 (6060).JPG',\n",
       " 'Dataset/images/rev19/39/39_20220528 (6289).JPG',\n",
       " 'Dataset/images/rev19/39/39_20220602 (6584).JPG',\n",
       " 'Dataset/images/rev19/39/39_20220604 (7023).JPG',\n",
       " 'Dataset/images/rev19/39/39_20220605 (7367).JPG',\n",
       " 'Dataset/images/rev19/39/39_20220606 (7678).JPG',\n",
       " 'Dataset/images/rev19/39/39_20220607 (8085).JPG',\n",
       " 'Dataset/images/rev19/39/39_20220610 (8562).JPG',\n",
       " 'Dataset/images/rev19/39/39_20220612 (8618).JPG',\n",
       " 'Dataset/images/rev19/41/41_20220510 (7).JPG',\n",
       " 'Dataset/images/rev19/41/41_20220510 (11).JPG',\n",
       " 'Dataset/images/rev19/41/41_20220510 (14).JPG',\n",
       " 'Dataset/images/rev19/41/41_20220602 (223).JPG',\n",
       " 'Dataset/images/rev19/41/41_20220611 (321).JPG',\n",
       " 'Dataset/images/rev19/42/42_20220510 (6).JPG',\n",
       " 'Dataset/images/rev19/48/48_20220510 (12).JPG',\n",
       " 'Dataset/images/rev19/48/48_20220511 (17).JPG',\n",
       " 'Dataset/images/rev19/48/48_20220515 (214).JPG',\n",
       " 'Dataset/images/rev19/48/48_20220518 (247).JPG',\n",
       " 'Dataset/images/rev19/48/48_20220518 (248).JPG',\n",
       " 'Dataset/images/rev19/48/48_20220519 (268).JPG',\n",
       " 'Dataset/images/rev19/48/48_20220519 (292).JPG',\n",
       " 'Dataset/images/rev19/48/48_20220523 (355).JPG',\n",
       " 'Dataset/images/rev19/48/48_20220523 (358).JPG',\n",
       " 'Dataset/images/rev19/48/48_20220526 (401).JPG',\n",
       " 'Dataset/images/rev19/48/48_20220526 (403).JPG',\n",
       " 'Dataset/images/rev19/48/48_20220529 (505).JPG',\n",
       " 'Dataset/images/rev19/48/48_20220602 (547).JPG',\n",
       " 'Dataset/images/rev19/48/48_20220613 (668).JPG',\n",
       " 'Dataset/images/rev19/51/51_20220516 (4590).JPG',\n",
       " 'Dataset/images/rev19/51/51_20220517 (7540).JPG',\n",
       " 'Dataset/images/rev19/51/51_20220518 (7812).JPG',\n",
       " 'Dataset/images/rev19/51/51_20220518 (7843).JPG',\n",
       " 'Dataset/images/rev19/51/51_20220520 (8430).JPG',\n",
       " 'Dataset/images/rev19/51/51_20220520 (8610).JPG',\n",
       " 'Dataset/images/rev19/51/51_20220524 (12289).JPG',\n",
       " 'Dataset/images/rev19/51/51_20220524 (12297).JPG',\n",
       " 'Dataset/images/rev19/51/51_20220524 (16671).JPG',\n",
       " 'Dataset/images/rev19/51/51_20220524 (18244).JPG',\n",
       " 'Dataset/images/rev19/51/51_20220525 (18299).JPG',\n",
       " 'Dataset/images/rev19/51/51_20220525 (19663).JPG',\n",
       " 'Dataset/images/rev19/51/51_20220525 (21720).JPG',\n",
       " 'Dataset/images/rev19/51/51_20220525 (21727).JPG',\n",
       " 'Dataset/images/rev19/47/47_20220510 (3).JPG',\n",
       " 'Dataset/images/rev19/47/47_20220512 (278).JPG',\n",
       " 'Dataset/images/rev19/47/47_20220512 (275).JPG',\n",
       " 'Dataset/images/rev19/47/47_20220512 (489).JPG',\n",
       " 'Dataset/images/rev19/47/47_20220513 (535).JPG',\n",
       " 'Dataset/images/rev19/47/47_20220517 (574).JPG',\n",
       " 'Dataset/images/rev19/47/47_20220519 (633).JPG',\n",
       " 'Dataset/images/rev19/47/47_20220525 (893).JPG',\n",
       " 'Dataset/images/rev19/47/47_20220527 (1128).JPG',\n",
       " 'Dataset/images/rev19/47/47_20220527 (1155).JPG',\n",
       " 'Dataset/images/rev19/47/47_20220602 (1446).JPG',\n",
       " 'Dataset/images/rev19/47/47_20220602 (1738).JPG',\n",
       " 'Dataset/images/rev19/47/47_20220602 (1808).JPG',\n",
       " 'Dataset/images/rev19/47/47_20220606 (2370).JPG',\n",
       " 'Dataset/images/rev19/47/47_20220606 (2380).JPG',\n",
       " 'Dataset/images/rev19/47/47_20220606 (2388).JPG',\n",
       " 'Dataset/images/rev19/47/47_20220610 (2588).JPG',\n",
       " 'Dataset/images/rev19/47/47_20220611 (2644).JPG',\n",
       " 'Dataset/images/rev19/8/8_20220512 (9).JPG',\n",
       " 'Dataset/images/rev19/8/8_20220512 (7).JPG',\n",
       " 'Dataset/images/rev19/8/8_20220512 (12).JPG',\n",
       " 'Dataset/images/rev19/9/9_20220510 (27).JPG',\n",
       " 'Dataset/images/rev19/9/9_20220510 (39).JPG',\n",
       " 'Dataset/images/rev19/9/9_20220511 (157).JPG',\n",
       " 'Dataset/images/rev19/9/9_20220523 (387).JPG',\n",
       " 'Dataset/images/rev19/9/9_20220526 (762).JPG',\n",
       " 'Dataset/images/rev19/9/9_20220527 (813).JPG',\n",
       " 'Dataset/images/rev19/9/9_20220529 (860).JPG',\n",
       " 'Dataset/images/rev19/9/9_20220529 (866).JPG',\n",
       " 'Dataset/images/rev19/9/9_20220530 (1089).JPG',\n",
       " 'Dataset/images/rev19/9/9_20220530 (1196).JPG',\n",
       " 'Dataset/images/rev19/9/9_20220611 (2882).JPG',\n",
       " 'Dataset/images/rev19/9/9_20220611 (3275).JPG',\n",
       " 'Dataset/images/rev19/9/9_20220611 (3323).JPG',\n",
       " 'Dataset/images/rev19/9/9_20220611 (3545).JPG',\n",
       " 'Dataset/images/rev19/9/9_20220611 (3560).JPG',\n",
       " 'Dataset/images/rev19/9/9_20220611 (3551).JPG',\n",
       " 'Dataset/images/rev20/10/10_20220610 (9).JPG',\n",
       " 'Dataset/images/rev20/10/10_20220611 (154).JPG',\n",
       " 'Dataset/images/rev20/10/10_20220616 (1373).JPG',\n",
       " 'Dataset/images/rev20/10/10_20220618 (1583).JPG',\n",
       " 'Dataset/images/rev20/10/10_20220623 (3171).JPG',\n",
       " 'Dataset/images/rev20/10/10_20220624 (3568).JPG',\n",
       " 'Dataset/images/rev20/10/10_20220627 (4610).JPG',\n",
       " 'Dataset/images/rev20/10/10_20220628 (4791).JPG',\n",
       " 'Dataset/images/rev20/10/10_20220630 (5664).JPG',\n",
       " 'Dataset/images/rev20/10/10_20220702 (6358).JPG',\n",
       " 'Dataset/images/rev20/10/10_20220703 (6413).JPG',\n",
       " 'Dataset/images/rev20/10/10_20220703 (6437).JPG',\n",
       " 'Dataset/images/rev20/10/10_20220705 (6973).JPG',\n",
       " 'Dataset/images/rev20/10/10_20220705 (6989).JPG',\n",
       " 'Dataset/images/rev20/10/10_20220707 (7500).JPG',\n",
       " 'Dataset/images/rev20/10/10_20220709 (7846).JPG',\n",
       " 'Dataset/images/rev20/10/10_20220709 (7915).JPG',\n",
       " 'Dataset/images/rev20/10/10_20220710 (8018).JPG',\n",
       " 'Dataset/images/rev20/10/10_20220714 (8715).JPG',\n",
       " 'Dataset/images/rev20/10/10_20220714 (8718).JPG',\n",
       " 'Dataset/images/rev20/10/10_20220714 (8739).JPG',\n",
       " 'Dataset/images/rev20/10/10_20220715 (9096).JPG',\n",
       " 'Dataset/images/rev20/10/10_20220716 (9262).JPG',\n",
       " 'Dataset/images/rev20/10/10_20220717 (9436).JPG',\n",
       " 'Dataset/images/rev20/10/10_20220720 (10050).JPG',\n",
       " 'Dataset/images/rev20/11/11_20220612 (43).JPG',\n",
       " 'Dataset/images/rev20/11/11_20220612 (141).JPG',\n",
       " 'Dataset/images/rev20/11/11_20220617 (384).JPG',\n",
       " 'Dataset/images/rev20/11/11_20220619 (807).JPG',\n",
       " 'Dataset/images/rev20/11/11_20220621 (1027).JPG',\n",
       " 'Dataset/images/rev20/11/11_20220622 (1261).JPG',\n",
       " 'Dataset/images/rev20/11/11_20220628 (2959).JPG',\n",
       " 'Dataset/images/rev20/11/11_20220629 (3043).JPG',\n",
       " 'Dataset/images/rev20/11/11_20220704 (3857).JPG',\n",
       " 'Dataset/images/rev20/11/11_20220705 (4053).JPG',\n",
       " 'Dataset/images/rev20/11/11_20220705 (4057).JPG',\n",
       " 'Dataset/images/rev20/11/11_20220708 (4236).JPG',\n",
       " 'Dataset/images/rev20/11/11_20220710 (4440).JPG',\n",
       " 'Dataset/images/rev20/11/11_20220710 (4543).JPG',\n",
       " 'Dataset/images/rev20/11/11_20220711 (4650).JPG',\n",
       " 'Dataset/images/rev20/11/11_20220713 (4814).JPG',\n",
       " 'Dataset/images/rev20/11/11_20220714 (4831).JPG',\n",
       " 'Dataset/images/rev20/11/11_20220715 (4991).JPG',\n",
       " 'Dataset/images/rev20/11/11_20220716 (5162).JPG',\n",
       " 'Dataset/images/rev20/11/11_20220722 (5755).JPG',\n",
       " 'Dataset/images/rev20/45/45_20220722 (101).JPG',\n",
       " 'Dataset/images/rev20/44/44_20220613 (1).JPG',\n",
       " 'Dataset/images/rev20/44/44_20220613 (11).JPG',\n",
       " 'Dataset/images/rev20/44/44_20220613 (5).JPG',\n",
       " 'Dataset/images/rev20/44/44_20220613 (15).JPG',\n",
       " 'Dataset/images/rev20/44/44_20220614 (16).JPG',\n",
       " 'Dataset/images/rev20/44/44_20220702 (391).JPG',\n",
       " 'Dataset/images/rev20/44/44_20220722 (666).JPG',\n",
       " 'Dataset/images/rev20/44/44_20220722 (657).JPG',\n",
       " 'Dataset/images/rev20/46/46_20220611 (8).JPG',\n",
       " 'Dataset/images/rev20/46/46_20220612 (54).JPG',\n",
       " 'Dataset/images/rev20/46/46_20220619 (179).JPG',\n",
       " 'Dataset/images/rev20/46/46_20220621 (743).JPG',\n",
       " 'Dataset/images/rev20/46/46_20220627 (1427).JPG',\n",
       " 'Dataset/images/rev20/46/46_20220627 (1448).JPG',\n",
       " 'Dataset/images/rev20/46/46_20220701 (1564).JPG',\n",
       " 'Dataset/images/rev20/46/46_20220701 (1599).JPG',\n",
       " 'Dataset/images/rev20/46/46_20220703 (1697).JPG',\n",
       " 'Dataset/images/rev20/46/46_20220708 (1744).JPG',\n",
       " 'Dataset/images/rev20/46/46_20220718 (1996).JPG',\n",
       " 'Dataset/images/rev20/46/46_20220718 (1994).JPG',\n",
       " 'Dataset/images/rev20/46/46_20220718 (1999).JPG',\n",
       " 'Dataset/images/rev20/46/46_20220718 (2016).JPG',\n",
       " 'Dataset/images/rev20/46/46_20220719 (2027).JPG',\n",
       " 'Dataset/images/rev20/46/46_20220722 (2126).JPG',\n",
       " 'Dataset/images/rev20/46/46_20220722 (2128).JPG',\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_list = df.transpose().values.tolist()\n",
    "\n",
    "#new = list(np.concatenate(imgs_list))\n",
    "\n",
    "# iterate through the sublist using List comprehension\n",
    "flatList = [element for innerList in imgs_list for element in innerList]\n",
    "\n",
    "flatList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alba/miniconda3/envs/cv4ecology/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from constants import *\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model from training results\n",
    "best_model = YOLO(\"../\" + MODEL_WEIGHTS_BEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/alba/cv4ecology/AI_Census/../Dataset/test/rev01/26/26_20201025 (193).JPG: 384x640 6 fallow deers, 2 red deers, 2 wild boars, 11.6ms\n",
      "Speed: 3.4ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict9\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# get predictions on best model\n",
    "#results = best_model.predict(\"../Dataset/test/rev01/26\", stream=True, save=True, conf=0.01)\n",
    "\n",
    "results = best_model.predict(\"../Dataset/test/rev01/26/26_20201025 (193).JPG\", save=True, conf=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ 'Boxes.boxes' is deprecated. Use 'Boxes.data' instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Boxes object with attributes:\n",
       "\n",
       "boxes: tensor([[1.1471e+03, 6.7072e+02, 1.3136e+03, 8.0634e+02, 6.7992e-01, 6.0000e+00],\n",
       "        [2.3434e+03, 4.7535e+02, 2.3984e+03, 9.5993e+02, 8.8367e-02, 6.0000e+00],\n",
       "        [2.3469e+03, 5.8889e+02, 2.3989e+03, 9.3905e+02, 3.4941e-02, 6.0000e+00],\n",
       "        [1.1503e+03, 6.7772e+02, 1.3158e+03, 8.0695e+02, 3.2849e-02, 1.2000e+01],\n",
       "        [1.1292e+03, 5.4484e+02, 1.3120e+03, 8.0783e+02, 2.8883e-02, 6.0000e+00],\n",
       "        [2.3486e+03, 7.2489e+02, 2.3984e+03, 9.3549e+02, 1.7575e-02, 1.4000e+01],\n",
       "        [1.1335e+03, 6.3546e+02, 1.3106e+03, 8.0621e+02, 1.6460e-02, 1.2000e+01],\n",
       "        [2.3493e+03, 6.0262e+02, 2.3990e+03, 9.4952e+02, 1.4116e-02, 1.4000e+01],\n",
       "        [2.3466e+03, 6.7092e+02, 2.3990e+03, 1.0141e+03, 1.1161e-02, 6.0000e+00],\n",
       "        [2.3481e+03, 7.2900e+02, 2.3992e+03, 9.3268e+02, 1.0307e-02, 6.0000e+00]], device='cuda:0')\n",
       "cls: tensor([ 6.,  6.,  6., 12.,  6., 14., 12., 14.,  6.,  6.], device='cuda:0')\n",
       "conf: tensor([0.6799, 0.0884, 0.0349, 0.0328, 0.0289, 0.0176, 0.0165, 0.0141, 0.0112, 0.0103], device='cuda:0')\n",
       "data: tensor([[1.1471e+03, 6.7072e+02, 1.3136e+03, 8.0634e+02, 6.7992e-01, 6.0000e+00],\n",
       "        [2.3434e+03, 4.7535e+02, 2.3984e+03, 9.5993e+02, 8.8367e-02, 6.0000e+00],\n",
       "        [2.3469e+03, 5.8889e+02, 2.3989e+03, 9.3905e+02, 3.4941e-02, 6.0000e+00],\n",
       "        [1.1503e+03, 6.7772e+02, 1.3158e+03, 8.0695e+02, 3.2849e-02, 1.2000e+01],\n",
       "        [1.1292e+03, 5.4484e+02, 1.3120e+03, 8.0783e+02, 2.8883e-02, 6.0000e+00],\n",
       "        [2.3486e+03, 7.2489e+02, 2.3984e+03, 9.3549e+02, 1.7575e-02, 1.4000e+01],\n",
       "        [1.1335e+03, 6.3546e+02, 1.3106e+03, 8.0621e+02, 1.6460e-02, 1.2000e+01],\n",
       "        [2.3493e+03, 6.0262e+02, 2.3990e+03, 9.4952e+02, 1.4116e-02, 1.4000e+01],\n",
       "        [2.3466e+03, 6.7092e+02, 2.3990e+03, 1.0141e+03, 1.1161e-02, 6.0000e+00],\n",
       "        [2.3481e+03, 7.2900e+02, 2.3992e+03, 9.3268e+02, 1.0307e-02, 6.0000e+00]], device='cuda:0')\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (1350, 2400)\n",
       "shape: torch.Size([10, 6])\n",
       "xywh: tensor([[1230.3815,  738.5304,  166.5066,  135.6254],\n",
       "        [2370.9150,  717.6398,   55.0115,  484.5748],\n",
       "        [2372.9236,  763.9732,   52.0464,  350.1613],\n",
       "        [1233.0179,  742.3328,  165.4766,  129.2333],\n",
       "        [1220.6006,  676.3361,  182.7113,  262.9914],\n",
       "        [2373.5269,  830.1945,   49.7629,  210.6006],\n",
       "        [1222.0166,  720.8337,  177.1000,  170.7549],\n",
       "        [2374.1399,  776.0707,   49.6479,  346.8970],\n",
       "        [2372.7764,  842.5265,   52.3718,  343.2049],\n",
       "        [2373.6826,  830.8411,   51.1331,  203.6740]], device='cuda:0')\n",
       "xywhn: tensor([[0.5127, 0.5471, 0.0694, 0.1005],\n",
       "        [0.9879, 0.5316, 0.0229, 0.3589],\n",
       "        [0.9887, 0.5659, 0.0217, 0.2594],\n",
       "        [0.5138, 0.5499, 0.0689, 0.0957],\n",
       "        [0.5086, 0.5010, 0.0761, 0.1948],\n",
       "        [0.9890, 0.6150, 0.0207, 0.1560],\n",
       "        [0.5092, 0.5340, 0.0738, 0.1265],\n",
       "        [0.9892, 0.5749, 0.0207, 0.2570],\n",
       "        [0.9887, 0.6241, 0.0218, 0.2542],\n",
       "        [0.9890, 0.6154, 0.0213, 0.1509]], device='cuda:0')\n",
       "xyxy: tensor([[1147.1282,  670.7177, 1313.6348,  806.3431],\n",
       "        [2343.4094,  475.3524, 2398.4209,  959.9272],\n",
       "        [2346.9004,  588.8926, 2398.9468,  939.0538],\n",
       "        [1150.2797,  677.7161, 1315.7562,  806.9494],\n",
       "        [1129.2450,  544.8403, 1311.9563,  807.8317],\n",
       "        [2348.6453,  724.8942, 2398.4082,  935.4948],\n",
       "        [1133.4666,  635.4563, 1310.5665,  806.2112],\n",
       "        [2349.3159,  602.6223, 2398.9639,  949.5192],\n",
       "        [2346.5903,  670.9240, 2398.9622, 1014.1289],\n",
       "        [2348.1160,  729.0042, 2399.2490,  932.6781]], device='cuda:0')\n",
       "xyxyn: tensor([[0.4780, 0.4968, 0.5473, 0.5973],\n",
       "        [0.9764, 0.3521, 0.9993, 0.7111],\n",
       "        [0.9779, 0.4362, 0.9996, 0.6956],\n",
       "        [0.4793, 0.5020, 0.5482, 0.5977],\n",
       "        [0.4705, 0.4036, 0.5466, 0.5984],\n",
       "        [0.9786, 0.5370, 0.9993, 0.6930],\n",
       "        [0.4723, 0.4707, 0.5461, 0.5972],\n",
       "        [0.9789, 0.4464, 0.9996, 0.7033],\n",
       "        [0.9777, 0.4970, 0.9996, 0.7512],\n",
       "        [0.9784, 0.5400, 0.9997, 0.6909]], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Results' object has no attribute 'get_field'. See valid attributes below.\n\n    A class for storing and manipulating inference results.\n\n    Args:\n        orig_img (numpy.ndarray): The original image as a numpy array.\n        path (str): The path to the image file.\n        names (dict): A dictionary of class names.\n        boxes (torch.tensor, optional): A 2D tensor of bounding box coordinates for each detection.\n        masks (torch.tensor, optional): A 3D tensor of detection masks, where each mask is a binary image.\n        probs (torch.tensor, optional): A 1D tensor of probabilities of each class for classification task.\n        keypoints (List[List[float]], optional): A list of detected keypoints for each object.\n\n    Attributes:\n        orig_img (numpy.ndarray): The original image as a numpy array.\n        orig_shape (tuple): The original image shape in (height, width) format.\n        boxes (Boxes, optional): A Boxes object containing the detection bounding boxes.\n        masks (Masks, optional): A Masks object containing the detection masks.\n        probs (Probs, optional): A Probs object containing probabilities of each class for classification task.\n        keypoints (Keypoints, optional): A Keypoints object containing detected keypoints for each object.\n        speed (dict): A dictionary of preprocess, inference, and postprocess speeds in milliseconds per image.\n        names (dict): A dictionary of class names.\n        path (str): The path to the image file.\n        _keys (tuple): A tuple of attribute names for non-empty attributes.\n    ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mget_field(\u001b[39m'\u001b[39m\u001b[39mscores\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ultralytics/utils/__init__.py:135\u001b[0m, in \u001b[0;36mSimpleClass.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001b[39;00m\n\u001b[1;32m    134\u001b[0m name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m--> 135\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. See valid attributes below.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__doc__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Results' object has no attribute 'get_field'. See valid attributes below.\n\n    A class for storing and manipulating inference results.\n\n    Args:\n        orig_img (numpy.ndarray): The original image as a numpy array.\n        path (str): The path to the image file.\n        names (dict): A dictionary of class names.\n        boxes (torch.tensor, optional): A 2D tensor of bounding box coordinates for each detection.\n        masks (torch.tensor, optional): A 3D tensor of detection masks, where each mask is a binary image.\n        probs (torch.tensor, optional): A 1D tensor of probabilities of each class for classification task.\n        keypoints (List[List[float]], optional): A list of detected keypoints for each object.\n\n    Attributes:\n        orig_img (numpy.ndarray): The original image as a numpy array.\n        orig_shape (tuple): The original image shape in (height, width) format.\n        boxes (Boxes, optional): A Boxes object containing the detection bounding boxes.\n        masks (Masks, optional): A Masks object containing the detection masks.\n        probs (Probs, optional): A Probs object containing probabilities of each class for classification task.\n        keypoints (Keypoints, optional): A Keypoints object containing detected keypoints for each object.\n        speed (dict): A dictionary of preprocess, inference, and postprocess speeds in milliseconds per image.\n        names (dict): A dictionary of class names.\n        path (str): The path to the image file.\n        _keys (tuple): A tuple of attribute names for non-empty attributes.\n    "
     ]
    }
   ],
   "source": [
    "results[0].get_field('scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Results' object has no attribute 'xyxyn'. See valid attributes below.\n\n    A class for storing and manipulating inference results.\n\n    Args:\n        orig_img (numpy.ndarray): The original image as a numpy array.\n        path (str): The path to the image file.\n        names (dict): A dictionary of class names.\n        boxes (torch.tensor, optional): A 2D tensor of bounding box coordinates for each detection.\n        masks (torch.tensor, optional): A 3D tensor of detection masks, where each mask is a binary image.\n        probs (torch.tensor, optional): A 1D tensor of probabilities of each class for classification task.\n        keypoints (List[List[float]], optional): A list of detected keypoints for each object.\n\n    Attributes:\n        orig_img (numpy.ndarray): The original image as a numpy array.\n        orig_shape (tuple): The original image shape in (height, width) format.\n        boxes (Boxes, optional): A Boxes object containing the detection bounding boxes.\n        masks (Masks, optional): A Masks object containing the detection masks.\n        probs (Probs, optional): A Probs object containing probabilities of each class for classification task.\n        keypoints (Keypoints, optional): A Keypoints object containing detected keypoints for each object.\n        speed (dict): A dictionary of preprocess, inference, and postprocess speeds in milliseconds per image.\n        names (dict): A dictionary of class names.\n        path (str): The path to the image file.\n        _keys (tuple): A tuple of attribute names for non-empty attributes.\n    ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Suppose you have a list of `result` objects for multiple images named `results`.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Then, you can loop through the list and for each `result` object, \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# you can access the `result.xyxyn` tensor to get the class probabilities for each bounding box. \u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m result \u001b[39min\u001b[39;00m results:\n\u001b[0;32m----> 6\u001b[0m     class_probs \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39;49mxyxyn[:, \u001b[39m5\u001b[39m]  \u001b[39m# get the class probability values for all bounding boxes in the image\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[39m# do something with the class probability values, such as store them in a list or a dictionary\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ultralytics/utils/__init__.py:135\u001b[0m, in \u001b[0;36mSimpleClass.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001b[39;00m\n\u001b[1;32m    134\u001b[0m name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m--> 135\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. See valid attributes below.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__doc__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Results' object has no attribute 'xyxyn'. See valid attributes below.\n\n    A class for storing and manipulating inference results.\n\n    Args:\n        orig_img (numpy.ndarray): The original image as a numpy array.\n        path (str): The path to the image file.\n        names (dict): A dictionary of class names.\n        boxes (torch.tensor, optional): A 2D tensor of bounding box coordinates for each detection.\n        masks (torch.tensor, optional): A 3D tensor of detection masks, where each mask is a binary image.\n        probs (torch.tensor, optional): A 1D tensor of probabilities of each class for classification task.\n        keypoints (List[List[float]], optional): A list of detected keypoints for each object.\n\n    Attributes:\n        orig_img (numpy.ndarray): The original image as a numpy array.\n        orig_shape (tuple): The original image shape in (height, width) format.\n        boxes (Boxes, optional): A Boxes object containing the detection bounding boxes.\n        masks (Masks, optional): A Masks object containing the detection masks.\n        probs (Probs, optional): A Probs object containing probabilities of each class for classification task.\n        keypoints (Keypoints, optional): A Keypoints object containing detected keypoints for each object.\n        speed (dict): A dictionary of preprocess, inference, and postprocess speeds in milliseconds per image.\n        names (dict): A dictionary of class names.\n        path (str): The path to the image file.\n        _keys (tuple): A tuple of attribute names for non-empty attributes.\n    "
     ]
    }
   ],
   "source": [
    "# Suppose you have a list of `result` objects for multiple images named `results`.\n",
    "# Then, you can loop through the list and for each `result` object, \n",
    "# you can access the `result.xyxyn` tensor to get the class probabilities for each bounding box. \n",
    "\n",
    "for result in results:\n",
    "    class_probs = result.xyxyn[:, 5]  # get the class probability values for all bounding boxes in the image\n",
    "    # do something with the class probability values, such as store them in a list or a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Results' object has no attribute 'xyxyn'. See valid attributes below.\n\n    A class for storing and manipulating inference results.\n\n    Args:\n        orig_img (numpy.ndarray): The original image as a numpy array.\n        path (str): The path to the image file.\n        names (dict): A dictionary of class names.\n        boxes (torch.tensor, optional): A 2D tensor of bounding box coordinates for each detection.\n        masks (torch.tensor, optional): A 3D tensor of detection masks, where each mask is a binary image.\n        probs (torch.tensor, optional): A 1D tensor of probabilities of each class for classification task.\n        keypoints (List[List[float]], optional): A list of detected keypoints for each object.\n\n    Attributes:\n        orig_img (numpy.ndarray): The original image as a numpy array.\n        orig_shape (tuple): The original image shape in (height, width) format.\n        boxes (Boxes, optional): A Boxes object containing the detection bounding boxes.\n        masks (Masks, optional): A Masks object containing the detection masks.\n        probs (Probs, optional): A Probs object containing probabilities of each class for classification task.\n        keypoints (Keypoints, optional): A Keypoints object containing detected keypoints for each object.\n        speed (dict): A dictionary of preprocess, inference, and postprocess speeds in milliseconds per image.\n        names (dict): A dictionary of class names.\n        path (str): The path to the image file.\n        _keys (tuple): A tuple of attribute names for non-empty attributes.\n    ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m results:\n\u001b[0;32m----> 2\u001b[0m     \u001b[39mprint\u001b[39m(r\u001b[39m.\u001b[39;49mxyxyn)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ultralytics/utils/__init__.py:135\u001b[0m, in \u001b[0;36mSimpleClass.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001b[39;00m\n\u001b[1;32m    134\u001b[0m name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m--> 135\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. See valid attributes below.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__doc__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Results' object has no attribute 'xyxyn'. See valid attributes below.\n\n    A class for storing and manipulating inference results.\n\n    Args:\n        orig_img (numpy.ndarray): The original image as a numpy array.\n        path (str): The path to the image file.\n        names (dict): A dictionary of class names.\n        boxes (torch.tensor, optional): A 2D tensor of bounding box coordinates for each detection.\n        masks (torch.tensor, optional): A 3D tensor of detection masks, where each mask is a binary image.\n        probs (torch.tensor, optional): A 1D tensor of probabilities of each class for classification task.\n        keypoints (List[List[float]], optional): A list of detected keypoints for each object.\n\n    Attributes:\n        orig_img (numpy.ndarray): The original image as a numpy array.\n        orig_shape (tuple): The original image shape in (height, width) format.\n        boxes (Boxes, optional): A Boxes object containing the detection bounding boxes.\n        masks (Masks, optional): A Masks object containing the detection masks.\n        probs (Probs, optional): A Probs object containing probabilities of each class for classification task.\n        keypoints (Keypoints, optional): A Keypoints object containing detected keypoints for each object.\n        speed (dict): A dictionary of preprocess, inference, and postprocess speeds in milliseconds per image.\n        names (dict): A dictionary of class names.\n        path (str): The path to the image file.\n        _keys (tuple): A tuple of attribute names for non-empty attributes.\n    "
     ]
    }
   ],
   "source": [
    "for r in results:\n",
    "    print(r.xyxyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "keys: ['boxes']\n",
      "masks: None\n",
      "names: {0: 'bird', 1: 'cow', 2: 'domestic dog', 3: 'egyptian mongoose', 4: 'european badger', 5: 'european rabbit', 6: 'fallow deer', 7: 'genet', 8: 'horse', 9: 'human', 10: 'iberian hare', 11: 'iberian lynx', 12: 'red deer', 13: 'red fox', 14: 'wild boar'}\n",
      "orig_img: array([[[215, 199, 193],\n",
      "        [223, 207, 201],\n",
      "        [234, 218, 211],\n",
      "        ...,\n",
      "        [245, 220, 248],\n",
      "        [248, 223, 251],\n",
      "        [253, 228, 255]],\n",
      "\n",
      "       [[192, 173, 168],\n",
      "        [195, 179, 172],\n",
      "        [200, 182, 175],\n",
      "        ...,\n",
      "        [172, 146, 170],\n",
      "        [175, 149, 173],\n",
      "        [182, 156, 180]],\n",
      "\n",
      "       [[183, 164, 157],\n",
      "        [184, 167, 158],\n",
      "        [183, 164, 156],\n",
      "        ...,\n",
      "        [121,  95, 111],\n",
      "        [120,  94, 112],\n",
      "        [126, 100, 118]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  4,   3,   0],\n",
      "        [  4,   3,   0],\n",
      "        [  4,   3,   0],\n",
      "        ...,\n",
      "        [  4,   3,   0],\n",
      "        [  4,   3,   0],\n",
      "        [  4,   3,   0]],\n",
      "\n",
      "       [[  4,   3,   0],\n",
      "        [  4,   3,   0],\n",
      "        [  4,   3,   0],\n",
      "        ...,\n",
      "        [  4,   3,   0],\n",
      "        [  4,   3,   0],\n",
      "        [  4,   3,   0]],\n",
      "\n",
      "       [[  4,   3,   0],\n",
      "        [  4,   3,   0],\n",
      "        [  4,   3,   0],\n",
      "        ...,\n",
      "        [  4,   3,   0],\n",
      "        [  4,   3,   0],\n",
      "        [  4,   3,   0]]], dtype=uint8)\n",
      "orig_shape: (1350, 2400)\n",
      "path: '/home/alba/cv4ecology/AI_Census/../Dataset/test/rev01/26/26_20201025 (193).JPG'\n",
      "probs: None\n",
      "save_dir: 'runs/detect/predict8'\n",
      "speed: {'preprocess': 1.394510269165039, 'inference': 9.770870208740234, 'postprocess': 1.9733905792236328}\n"
     ]
    }
   ],
   "source": [
    "# Perform object detection on an image using the model\n",
    "# results = model('https://ultralytics.com/images/bus.jpg')\n",
    "\n",
    "# What Manuel wanted :´) -> for classification model, will it work with detection???????????????????\n",
    "'''# Run inference on an image\n",
    "results = model('bus.jpg')  # results list'''\n",
    "\n",
    "# View results\n",
    "for r in results:\n",
    "    print(r)  # print the Probs object containing the detected class probabilities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
